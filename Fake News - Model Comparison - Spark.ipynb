{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detector - Model comparison\n",
    "\n",
    "## Authors\n",
    "- Jose Garzon\n",
    "- Germán Patiño\n",
    "- Alejandro Salazar\n",
    "\n",
    "*Universidad EAFIT*\n",
    "## References\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb\n",
    "* https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 5.3.3\n",
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import sparknlp\n",
    "\n",
    "ss = sparknlp.start(gpu=True) \n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", ss.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion for conver Pandas Dataframe to Spark Dataframe\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n",
    "def read_data(path):\n",
    "  schema= StructType(\n",
    "      [StructField('title',StringType(),True),\n",
    "      StructField('text',StringType(),True),\n",
    "      StructField('label',IntegerType(),True)])\n",
    "  pd_df= pd.read_csv(path).drop('Unnamed: 0', axis= 1)\n",
    "  sp_df= ss.createDataFrame(pd_df, schema= schema)\n",
    "  return sp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data set\n",
    "path_data= 'WELFake_Dataset.csv'\n",
    "data= read_data(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, coalesce, lit, when, col, isnan\n",
    "\n",
    "# Define the transformation logic to create the full_text column\n",
    "data = data.withColumn(\n",
    "    \"full_text\",\n",
    "    concat(\n",
    "        coalesce(when(col(\"title\").isNotNull() & ~isnan(col(\"title\")), col(\"title\")).otherwise(lit(\"\")), lit(\"\")),\n",
    "        lit(\" \"),\n",
    "        coalesce(when(col(\"text\").isNotNull() & ~isnan(col(\"text\")), col(\"text\")).otherwise(lit(\"\")), lit(\"\"))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|               title|                text|label|           full_text|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|LAW ENFORCEMENT O...|No comment is exp...|    1|LAW ENFORCEMENT O...|\n",
      "|                 NaN|Did they post the...|    1| Did they post th...|\n",
      "|UNBELIEVABLE! OBA...| Now, most of the...|    1|UNBELIEVABLE! OBA...|\n",
      "|Bobby Jindal, rai...|A dozen political...|    0|Bobby Jindal, rai...|\n",
      "|SATAN 2: Russia u...|The RS-28 Sarmat ...|    1|SATAN 2: Russia u...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset, testDataset= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_uncased download started this may take some time.\n",
      "Approximate size to download 392,5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"full_text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bert_embeddings = BertEmbeddings().pretrained(name='bert_base_uncased', lang='en') \\\n",
    "    .setInputCols([\"document\",'token'])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setMaxEpochs(10)\\\n",
    "    .setLr(0.001)\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setEnableOutputLogs(True) \\\n",
    "    .setOutputLogsPath('logs')\n",
    "\n",
    "bert_clf_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        bert_embeddings,\n",
    "        embeddingsSentence,\n",
    "        classsifierdl\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.59 s\n",
      "Wall time: 2h 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_clf_pipelineModel = bert_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_clf_pipelineModel.transform(testDataset)\n",
    "preds_df = preds.select('label','full_text',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      7047\n",
      "           1       0.95      0.97      0.96      7464\n",
      "\n",
      "    accuracy                           0.96     14511\n",
      "   macro avg       0.96      0.96      0.96     14511\n",
      "weighted avg       0.96      0.96      0.96     14511\n",
      "\n",
      "0.9588587967748604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(preds_df.label, preds_df.result))\n",
    "print(accuracy_score(preds_df.label, preds_df.result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_a2e80a272cff,\n",
       " REGEX_TOKENIZER_981c8ad0aa49,\n",
       " BERT_EMBEDDINGS_4fbd72cbda5a,\n",
       " SentenceEmbeddings_36456b97f769,\n",
       " ClassifierDLModel_d66c1e805494]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf_pipelineModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_clf_pipelineModel.stages[-1].write().overwrite().save('ClassifierDLModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"full_text\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=20) #minDocFreq: remove sparse terms\n",
    "\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner,\n",
    "            stemmer,\n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf])\n",
    "\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(data)\n",
    "\n",
    "processed_tf = nlp_model_tf.transform(data)\n",
    "\n",
    "processed_tf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|           full_text|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|LAW ENFORCEMENT O...|(10000,[29,71,88,...|    1|\n",
      "| Did they post th...|(10000,[568,2460,...|    1|\n",
      "|UNBELIEVABLE! OBA...|(10000,[639,1226,...|    1|\n",
      "|Bobby Jindal, rai...|(10000,[15,24,39,...|    0|\n",
      "|SATAN 2: Russia u...|(10000,[33,58,63,...|    1|\n",
      "|About Time! Chris...|(10000,[171,387,5...|    1|\n",
      "|DR BEN CARSON TAR...|(10000,[281,472,1...|    1|\n",
      "|HOUSE INTEL CHAIR...|(10000,[472,681,7...|    1|\n",
      "|Sports Bar Owner ...|(10000,[24,35,88,...|    1|\n",
      "|Latest Pipeline L...|(10000,[104,116,1...|    1|\n",
      "| GOP Senator Just...|(10000,[35,58,150...|    1|\n",
      "|May Brexit offer ...|(10000,[8,23,29,1...|    0|\n",
      "|Schumer calls on ...|(10000,[15,51,52,...|    0|\n",
      "|WATCH: HILARIOUS ...|(10000,[493,568,7...|    1|\n",
      "|No Change Expecte...|(10000,[4,29,151,...|    0|\n",
      "|Billionaire Odebr...|(10000,[63,158,25...|    0|\n",
      "|BRITISH WOMAN LOS...|(10000,[15,57,158...|    1|\n",
      "|U.N. seeks humani...|(10000,[70,171,30...|    0|\n",
      "|MAJOR LIBERAL RAG...|(10000,[2,15,19,4...|    1|\n",
      "|Second judge says...|(10000,[23,51,171...|    0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_tf.select('full_text','features','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 57661\n",
      "Test Dataset Count: 14473\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(trainingData, testData) = processed_tf.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "lrModel_tf = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Islamic State Claims Respon...|[0.9999999999986016,1.39843...|    0|       0.0|\n",
      "|Trump vs. Congress: Now Wha...|[0.9999999983208085,1.67919...|    0|       0.0|\n",
      "|When to Leave on Your Thank...|[0.9999623778332197,3.76221...|    0|       0.0|\n",
      "|Taxpayers Will Defend Trump...|[0.9999229752678362,7.70247...|    0|       0.0|\n",
      "|Tragedy Made Steve Kerr See...|[0.9998925738626535,1.07426...|    0|       0.0|\n",
      "|Factbox: Trump finishes fil...|[0.9997803775513411,2.19622...|    0|       0.0|\n",
      "|More Than 160 Republicans D...|[0.9997710723021959,2.28927...|    0|       0.0|\n",
      "|Across the World, Shock and...|[0.9997576901769588,2.42309...|    0|       0.0|\n",
      "|How U.S. Torture Left a Leg...|[0.9997542467582056,2.45753...|    0|       0.0|\n",
      "|One Family. Six Decades. My...|[0.9996110151055642,3.88984...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tf = lrModel_tf.transform(testData)\n",
    "predictions_tf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      6994\n",
      "           1       0.93      0.96      0.94      7479\n",
      "\n",
      "    accuracy                           0.94     14473\n",
      "   macro avg       0.94      0.94      0.94     14473\n",
      "weighted avg       0.94      0.94      0.94     14473\n",
      "\n",
      "0.9416154218199406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_true = predictions_tf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_tf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel_tf.save('lrModel_tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|As clock ticks, Republicans...|[0.6767145373029972,0.32328...|    0|       0.0|\n",
      "|EU-U.S. trade deal in doubt...|[0.674859943165003,0.325140...|    0|       0.0|\n",
      "|Trump Shifting Authority Ov...|[0.6733586222002496,0.32664...|    0|       0.0|\n",
      "|Trump stars and spars with ...|[0.6728863883598141,0.32711...|    0|       0.0|\n",
      "|Fury at top of Republican P...|[0.6694708251088034,0.33052...|    0|       0.0|\n",
      "|Factbox: Trump finishes fil...|[0.6694538103456622,0.33054...|    0|       0.0|\n",
      "|'Glimmer of hope' seen for ...|[0.6684456063353668,0.33155...|    0|       0.0|\n",
      "|Trump to press China on Nor...|[0.6676187169463729,0.33238...|    0|       0.0|\n",
      "|Obama Administration Consid...|[0.6670200786920549,0.33297...|    0|       0.0|\n",
      "|Britain to detail Brexit bi...|[0.6662333482219233,0.33376...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = rfModel.transform(testData)\n",
    "predictions_rf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      6994\n",
      "           1       0.85      0.93      0.89      7479\n",
      "\n",
      "    accuracy                           0.88     14473\n",
      "   macro avg       0.88      0.87      0.88     14473\n",
      "weighted avg       0.88      0.88      0.88     14473\n",
      "\n",
      "0.8764596144545015\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions_rf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_rf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel.save('rfModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
