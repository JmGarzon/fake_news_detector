{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detector - Model comparison\n",
    "\n",
    "## Authors\n",
    "- Jose Garzon\n",
    "- Germán Patiño\n",
    "- Alejandro Salazar\n",
    "\n",
    "*Universidad EAFIT*\n",
    "## References\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb\n",
    "* https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Data handling\n",
    "from pyspark.sql.functions import concat, coalesce, lit, when, col, isnan\n",
    "\n",
    "# Spark ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory of the script\n",
    "current_dir = Path().resolve()\n",
    "\n",
    "MODEL_FOLDER = \".\\models\"\n",
    "LOGS_FOLDER = \".\\logs\"\n",
    "DATA_FOLDER = r\".\\data\\news_data\"\n",
    "\n",
    "model_path = current_dir.parent / MODEL_FOLDER\n",
    "logs_path = current_dir.parent / LOGS_FOLDER\n",
    "data_path = current_dir.parent / DATA_FOLDER\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(logs_path):\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Spark NLP version 5.3.3\n",
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "ss = sparknlp.start(gpu=True) \n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", ss.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data set\n",
    "data = ss.read.parquet(str(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and text columns into the full_text column, removing blank or null values.\n",
    "data = data.withColumn(\n",
    "    \"full_text\",\n",
    "    concat(\n",
    "        coalesce(when(col(\"title\").isNotNull() & ~isnan(col(\"title\")), col(\"title\")).otherwise(lit(\"\")), lit(\"\")),\n",
    "        lit(\" \"),\n",
    "        coalesce(when(col(\"text\").isNotNull() & ~isnan(col(\"text\")), col(\"text\")).otherwise(lit(\"\")), lit(\"\"))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|               title|                text|label|           full_text|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|The Week In Pictu...|New Report Finds ...|    1|The Week In Pictu...|\n",
      "|State Department ...|WASHINGTON – The ...|    0|State Department ...|\n",
      "|If Hillary Clinto...|Archives Michael ...|    1|If Hillary Clinto...|\n",
      "|Extreme rhetoric ...|The use of extrem...|    0|Extreme rhetoric ...|\n",
      "|UFO Investigator ...|link a reply to: ...|    1|UFO Investigator ...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data sample:\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 66793\n"
     ]
    }
   ],
   "source": [
    "record_counts = data.count()\n",
    "print(f\"Total records: {record_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed records: 66793\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"full_text\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=20) #minDocFreq: remove sparse terms\n",
    "\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner,\n",
    "            stemmer,\n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf])\n",
    "\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(data)\n",
    "\n",
    "processed_tf = nlp_model_tf.transform(data)\n",
    "\n",
    "tfidf_records = processed_tf.count()\n",
    "print(f\"Transformed records: {record_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized features:\n",
      "+--------------------+--------------------+-----+\n",
      "|           full_text|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|The Week In Pictu...|(10000,[68,276,32...|    1|\n",
      "|State Department ...|(10000,[8,130,221...|    0|\n",
      "|If Hillary Clinto...|(10000,[0,7,70,15...|    1|\n",
      "|Extreme rhetoric ...|(10000,[15,46,88,...|    0|\n",
      "|UFO Investigator ...|(10000,[5,57,193,...|    1|\n",
      "|The Left Turns on...|(10000,[15,236,29...|    1|\n",
      "|Comment on “This ...|(10000,[7,8,29,33...|    1|\n",
      "|Trump controlled ...|(10000,[15,84,96,...|    1|\n",
      "|Blame Government,...|(10000,[7,19,33,7...|    1|\n",
      "|Trump suggests he...|(10000,[193,236,2...|    0|\n",
      "|Sniff your undera...|(10000,[453,1468,...|    1|\n",
      "|Selected Not Elec...|(10000,[15,30,55,...|    1|\n",
      "|What Trump Will N...|(10000,[7,24,55,7...|    0|\n",
      "|The real reason t...|(10000,[63,70,145...|    0|\n",
      "|Clinton Says She ...|(10000,[158,281,3...|    0|\n",
      "|How the swing vot...|(10000,[0,15,29,1...|    0|\n",
      "|Islamic State cla...|(10000,[6,8,52,55...|    0|\n",
      "|To Protect and Sw...|(10000,[6,8,23,29...|    1|\n",
      "|Hillary Clinton's...|(10000,[32,40,51,...|    0|\n",
      "|Putting President...|(10000,[323,366,5...|    0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show vectorized features\n",
    "print(\"Vectorized features:\")\n",
    "processed_tf.select('full_text','features','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 53334\n",
      "Test Dataset Count: 13459\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(trainingData, testData) = processed_tf.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(f\"Training Dataset Count: {trainingData.count()}\")\n",
    "print(f\"Test Dataset Count: {testData.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "lrModel_tf = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|The Secret History of Colom...|[0.9999999288621939,7.11378...|    0|       0.0|\n",
      "|A Saudi Morals Enforcer Cal...|[0.999996911835493,3.088164...|    0|       0.0|\n",
      "|Where Even Nightmares Are C...|[0.9999879259482756,1.20740...|    0|       0.0|\n",
      "|Katinka Hosszu and Her Husb...|[0.9999834210454314,1.65789...|    0|       0.0|\n",
      "|As campaigns launch, poll f...|[0.9999475755424966,5.24244...|    0|       0.0|\n",
      "|How the Obama White House r...|[0.999931316742936,6.868325...|    0|       0.0|\n",
      "|United States v. Texas, the...|[0.999872649353562,1.273506...|    0|       0.0|\n",
      "|The Daily 202: How Democrat...|[0.9998405588006547,1.59441...|    0|       0.0|\n",
      "|Factbox: Trump fills top jo...|[0.9998289655949362,1.71034...|    0|       0.0|\n",
      "|Factbox: Trump finishes fil...|[0.9998287481860509,1.71251...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tf = lrModel_tf.transform(testData)\n",
    "predictions_tf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      7213\n",
      "           1       0.92      0.94      0.93      6246\n",
      "\n",
      "    accuracy                           0.93     13459\n",
      "   macro avg       0.93      0.93      0.93     13459\n",
      "weighted avg       0.93      0.93      0.93     13459\n",
      "\n",
      "0.9309755553904451\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true = predictions_tf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_tf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LR_Model_tf\"\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "lrModel_tf.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Syria Strike Puts U.S. Rela...|[0.7125964365460536,0.28740...|    0|       0.0|\n",
      "|Senate takes step toward pa...|[0.7104522226548046,0.28954...|    0|       0.0|\n",
      "|Trump outlines plans for fi...|[0.7091418132233812,0.29085...|    0|       0.0|\n",
      "|Trump urges 'strong and swi...|[0.7076387378880427,0.29236...|    0|       0.0|\n",
      "|Tillerson urges 'new approa...|[0.7060153083002274,0.29398...|    0|       0.0|\n",
      "|Separate mothers and childr...|[0.7053842739279532,0.29461...|    0|       0.0|\n",
      "|Palestinians to snub Pence ...|[0.7045675853958024,0.29543...|    0|       0.0|\n",
      "|Carson signals exit, U.S. R...|[0.7037308215783893,0.29626...|    0|       0.0|\n",
      "|Facing revolt on healthcare...|[0.7020194300912339,0.29798...|    0|       0.0|\n",
      "|Executive actions ready to ...|[0.699571213477347,0.300428...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = rfModel.transform(testData)\n",
    "predictions_rf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      7213\n",
      "           1       0.93      0.69      0.79      6246\n",
      "\n",
      "    accuracy                           0.83     13459\n",
      "   macro avg       0.85      0.82      0.83     13459\n",
      "weighted avg       0.85      0.83      0.83     13459\n",
      "\n",
      "0.8323798201946653\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions_rf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_rf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RF_Model\"\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "rfModel.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "trainDataset, testDataset= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_uncased download started this may take some time.\n",
      "Approximate size to download 392,5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"full_text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bert_embeddings = BertEmbeddings().pretrained(name='bert_base_uncased', lang='en') \\\n",
    "    .setInputCols([\"document\",'token'])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setMaxEpochs(10)\\\n",
    "    .setLr(0.001)\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setEnableOutputLogs(True) \\\n",
    "    .setOutputLogsPath('logs')\n",
    "\n",
    "bert_clf_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        bert_embeddings,\n",
    "        embeddingsSentence,\n",
    "        classsifierdl\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 1h 59min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_clf_pipelineModel = bert_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_clf_pipelineModel.transform(testDataset)\n",
    "preds_df = preds.select('label','full_text',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      7124\n",
      "           1       0.92      0.97      0.95      6200\n",
      "\n",
      "    accuracy                           0.95     13324\n",
      "   macro avg       0.95      0.95      0.95     13324\n",
      "weighted avg       0.95      0.95      0.95     13324\n",
      "\n",
      "0.9487391173821675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(preds_df.label, preds_df.result))\n",
    "print(accuracy_score(preds_df.label, preds_df.result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_e0bee2632907,\n",
       " REGEX_TOKENIZER_7affb0229300,\n",
       " BERT_EMBEDDINGS_4fbd72cbda5a,\n",
       " SentenceEmbeddings_fcafc5ffbad2,\n",
       " ClassifierDLModel_2a5937e2406e]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf_pipelineModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file:///C:/Users/jmgarzonv/Desktop/EAFIT/MMDS/models/BERT_ClassifierDL_Layer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"BERT_ClassifierDL_Layer\"\n",
    "model_filepath = model_path / model_name\n",
    "model_filepath = model_filepath.as_uri()\n",
    "print(f\"Saving model to {model_filepath}\")\n",
    "bert_clf_pipelineModel.stages[-1].write().overwrite().save(f\"{model_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
