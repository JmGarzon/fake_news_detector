{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detector - Model comparison\n",
    "\n",
    "## Authors\n",
    "- Jose Garzon\n",
    "- Germán Patiño\n",
    "- Alejandro Salazar\n",
    "\n",
    "*Universidad EAFIT*\n",
    "## References\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb\n",
    "* https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Data handling\n",
    "from pyspark.sql.functions import concat, coalesce, lit, when, col, isnan\n",
    "\n",
    "# Spark ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory of the script\n",
    "current_dir = Path().resolve()\n",
    "\n",
    "MODEL_FOLDER = \".\\models\"\n",
    "LOGS_FOLDER = \".\\logs\"\n",
    "DATA_FOLDER = r\".\\data\\news_data\"\n",
    "\n",
    "model_path = current_dir.parent / MODEL_FOLDER\n",
    "logs_path = current_dir.parent / LOGS_FOLDER\n",
    "data_path = current_dir.parent / DATA_FOLDER\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(logs_path):\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 5.3.3\n",
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "ss = sparknlp.start(gpu=True) \n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", ss.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data set\n",
    "data = ss.read.parquet(str(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and text columns into the full_text column, removing blank or null values.\n",
    "data = data.withColumn(\n",
    "    \"full_text\",\n",
    "    concat(\n",
    "        coalesce(when(col(\"title\").isNotNull() & ~isnan(col(\"title\")), col(\"title\")).otherwise(lit(\"\")), lit(\"\")),\n",
    "        lit(\" \"),\n",
    "        coalesce(when(col(\"text\").isNotNull() & ~isnan(col(\"text\")), col(\"text\")).otherwise(lit(\"\")), lit(\"\"))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|               title|                text|label|           full_text|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|NAZI Flying Sauce...|. NAZI Flying Sau...|    1|NAZI Flying Sauce...|\n",
      "|Mitt Romney Calls...|The most recent R...|    0|Mitt Romney Calls...|\n",
      "|Clinton takes the...|PHILADELPHIA — Ch...|    0|Clinton takes the...|\n",
      "|The Deteriorating...|Tweet Widget by Y...|    1|The Deteriorating...|\n",
      "|Old rivals Obama ...|Washington (CNN) ...|    0|Old rivals Obama ...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data sample:\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 66793\n"
     ]
    }
   ],
   "source": [
    "record_counts = data.count()\n",
    "print(f\"Total records: {record_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed records: 66793\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 6min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"full_text\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=20) #minDocFreq: remove sparse terms\n",
    "\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner,\n",
    "            stemmer,\n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf])\n",
    "\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(data)\n",
    "\n",
    "processed_tf = nlp_model_tf.transform(data)\n",
    "\n",
    "tfidf_records = processed_tf.count()\n",
    "print(f\"Transformed records: {record_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized features:\n",
      "+--------------------+--------------------+-----+\n",
      "|           full_text|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|NAZI Flying Sauce...|(10000,[8,15,28,2...|    1|\n",
      "|Mitt Romney Calls...|(10000,[15,23,51,...|    0|\n",
      "|Clinton takes the...|(10000,[7,9,29,15...|    0|\n",
      "|The Deteriorating...|(10000,[4,8,15,23...|    1|\n",
      "|Old rivals Obama ...|(10000,[19,145,16...|    0|\n",
      "|George Soros begi...|(10000,[30,58,70,...|    1|\n",
      "|Donald Trump is d...|(10000,[33,230,26...|    0|\n",
      "|How To Open Your ...|(10000,[1045,1480...|    1|\n",
      "|VA Secretary Robe...|(10000,[43,55,281...|    0|\n",
      "|Three Likely GOP ...|(10000,[230,323,3...|    0|\n",
      "|Ryan Endorses Tru...|(10000,[323,332,3...|    0|\n",
      "|Podesta WikiLeaks...|(10000,[8,15,20,2...|    1|\n",
      "|3 Year Old Son of...|(10000,[5,7,15,24...|    1|\n",
      "|The inane spectac...|(10000,[7,15,21,3...|    0|\n",
      "|Clinton “Fixer”: ...|(10000,[7,13,15,2...|    1|\n",
      "|Slain reporter's ...|(10000,[15,40,55,...|    0|\n",
      "|Hillary Clinton’s...|(10000,[0,13,15,2...|    0|\n",
      "|Obama administrat...|(10000,[30,33,52,...|    0|\n",
      "|Marco Rubio: Bein...|(10000,[149,323,4...|    0|\n",
      "|FRENCH COLLEGE ST...|(10000,[155,158,2...|    1|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show vectorized features\n",
    "print(\"Vectorized features:\")\n",
    "processed_tf.select('full_text','features','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 53489\n",
      "Test Dataset Count: 13304\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(trainingData, testData) = processed_tf.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(f\"Training Dataset Count: {trainingData.count()}\")\n",
    "print(f\"Test Dataset Count: {testData.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               title|                text|label|           full_text|            document|               token|          normalized|         cleanTokens|                stem|      token_features|         rawFeatures|            features|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|NAZI Flying Sauce...|. NAZI Flying Sau...|    1|NAZI Flying Sauce...|[{document, 0, 22...|[{token, 0, 3, NA...|[{token, 0, 3, NA...|[{token, 0, 3, NA...|[{token, 0, 3, na...|[nazi, fly, sauce...|(10000,[8,15,28,2...|(10000,[8,15,28,2...|\n",
      "|Mitt Romney Calls...|The most recent R...|    0|Mitt Romney Calls...|[{document, 0, 47...|[{token, 0, 3, Mi...|[{token, 0, 3, Mi...|[{token, 0, 3, Mi...|[{token, 0, 3, mi...|[mitt, romnei, ca...|(10000,[15,23,51,...|(10000,[15,23,51,...|\n",
      "|Clinton takes the...|PHILADELPHIA — Ch...|    0|Clinton takes the...|[{document, 0, 52...|[{token, 0, 6, Cl...|[{token, 0, 6, Cl...|[{token, 0, 6, Cl...|[{token, 0, 6, cl...|[clinton, take, f...|(10000,[7,9,29,15...|(10000,[7,9,29,15...|\n",
      "|The Deteriorating...|Tweet Widget by Y...|    1|The Deteriorating...|[{document, 0, 17...|[{token, 0, 2, Th...|[{token, 0, 2, Th...|[{token, 4, 16, D...|[{token, 4, 16, d...|[deterior, situat...|(10000,[4,8,15,23...|(10000,[4,8,15,23...|\n",
      "|Old rivals Obama ...|Washington (CNN) ...|    0|Old rivals Obama ...|[{document, 0, 41...|[{token, 0, 2, Ol...|[{token, 0, 2, Ol...|[{token, 0, 2, Ol...|[{token, 0, 2, ol...|[old, rival, obam...|(10000,[19,145,16...|(10000,[19,145,16...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_tf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "lrModel_tf = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "cleanTokens: 0.015486766977184737\n",
      "stem: 0.009106829343224716\n",
      "full_text: 0.009008630247096498\n",
      "token: 0.0069474023453024395\n",
      "normalized: 0.004120438724842986\n",
      "features: 0.003288882139715052\n",
      "token_features: 0.0029783775822809317\n",
      "rawFeatures: 0.0021202385389569945\n",
      "text: 0.0016053343916492486\n",
      "title: 0.001539909823722744\n",
      "document: 0.0012439575180319103\n",
      "label: 0.0010352675667627481\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients\n",
    "coefficients = lrModel_tf.coefficients\n",
    "intercept = lrModel_tf.intercept\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = [(feature, abs(coeff)) for feature, coeff in zip(trainingData.columns, coefficients)]\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display feature importance\n",
    "print(\"Feature importance:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Potential Conflicts Around ...|[0.999999969762807,3.023719...|    0|       0.0|\n",
      "|How Egypt’s Activists Becam...|[0.999997816840309,2.183159...|    0|       0.0|\n",
      "|Special Report: 'Treacherou...|[0.9999974247048143,2.57529...|    0|       0.0|\n",
      "|Katinka Hosszu and Her Husb...|[0.9999953700575471,4.62994...|    0|       0.0|\n",
      "|Where Even Nightmares Are C...|[0.9999651017637986,3.48982...|    0|       0.0|\n",
      "|How China Won the Keys to D...|[0.9999460763301009,5.39236...|    0|       0.0|\n",
      "|Kevin McCarthy drops out of...|[0.9999168979911142,8.31020...|    0|       0.0|\n",
      "|More Than 160 Republicans D...|[0.9999116677458976,8.83322...|    0|       0.0|\n",
      "|United States v. Texas, the...|[0.9999029113864484,9.70886...|    0|       0.0|\n",
      "|**Livewire** President Trum...|[0.9999014582412316,9.85417...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tf = lrModel_tf.transform(testData)\n",
    "predictions_tf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      7140\n",
      "           1       0.92      0.93      0.92      6164\n",
      "\n",
      "    accuracy                           0.93     13304\n",
      "   macro avg       0.93      0.93      0.93     13304\n",
      "weighted avg       0.93      0.93      0.93     13304\n",
      "\n",
      "0.9296452194828623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true = predictions_tf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_tf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LR_Model_tf\"\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "lrModel_tf.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Syria Strike Puts U.S. Rela...|[0.7125964365460536,0.28740...|    0|       0.0|\n",
      "|Senate takes step toward pa...|[0.7104522226548046,0.28954...|    0|       0.0|\n",
      "|Trump outlines plans for fi...|[0.7091418132233812,0.29085...|    0|       0.0|\n",
      "|Trump urges 'strong and swi...|[0.7076387378880427,0.29236...|    0|       0.0|\n",
      "|Tillerson urges 'new approa...|[0.7060153083002274,0.29398...|    0|       0.0|\n",
      "|Separate mothers and childr...|[0.7053842739279532,0.29461...|    0|       0.0|\n",
      "|Palestinians to snub Pence ...|[0.7045675853958024,0.29543...|    0|       0.0|\n",
      "|Carson signals exit, U.S. R...|[0.7037308215783893,0.29626...|    0|       0.0|\n",
      "|Facing revolt on healthcare...|[0.7020194300912339,0.29798...|    0|       0.0|\n",
      "|Executive actions ready to ...|[0.699571213477347,0.300428...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = rfModel.transform(testData)\n",
    "predictions_rf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      7213\n",
      "           1       0.93      0.69      0.79      6246\n",
      "\n",
      "    accuracy                           0.83     13459\n",
      "   macro avg       0.85      0.82      0.83     13459\n",
      "weighted avg       0.85      0.83      0.83     13459\n",
      "\n",
      "0.8323798201946653\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions_rf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_rf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RF_Model\"\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "rfModel.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "trainDataset, testDataset= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_uncased download started this may take some time.\n",
      "Approximate size to download 392,5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"full_text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bert_embeddings = BertEmbeddings().pretrained(name='bert_base_uncased', lang='en') \\\n",
    "    .setInputCols([\"document\",'token'])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setMaxEpochs(10)\\\n",
    "    .setLr(0.001)\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setEnableOutputLogs(True) \\\n",
    "    .setOutputLogsPath('logs')\n",
    "\n",
    "bert_clf_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        bert_embeddings,\n",
    "        embeddingsSentence,\n",
    "        classsifierdl\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 1h 59min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_clf_pipelineModel = bert_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_clf_pipelineModel.transform(testDataset)\n",
    "preds_df = preds.select('label','full_text',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      7124\n",
      "           1       0.92      0.97      0.95      6200\n",
      "\n",
      "    accuracy                           0.95     13324\n",
      "   macro avg       0.95      0.95      0.95     13324\n",
      "weighted avg       0.95      0.95      0.95     13324\n",
      "\n",
      "0.9487391173821675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(preds_df.label, preds_df.result))\n",
    "print(accuracy_score(preds_df.label, preds_df.result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_e0bee2632907,\n",
       " REGEX_TOKENIZER_7affb0229300,\n",
       " BERT_EMBEDDINGS_4fbd72cbda5a,\n",
       " SentenceEmbeddings_fcafc5ffbad2,\n",
       " ClassifierDLModel_2a5937e2406e]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf_pipelineModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file:///C:/Users/jmgarzonv/Desktop/EAFIT/MMDS/models/BERT_ClassifierDL_Layer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"BERT_ClassifierDL_Layer\"\n",
    "model_filepath = model_path / model_name\n",
    "model_filepath = model_filepath.as_uri()\n",
    "print(f\"Saving model to {model_filepath}\")\n",
    "bert_clf_pipelineModel.stages[-1].write().overwrite().save(f\"{model_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
